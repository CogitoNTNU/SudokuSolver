{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflowjs as tfjs\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "import builtins\n",
    "open = builtins.open\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_path = \"../website/prisma/seeding/labels.bin\"\n",
    "digits_path = \"../website/prisma/seeding/digits.bin\"\n",
    "model_path = \"new_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(x: np.ndarray, y: np.ndarray) -> tuple[tuple[np.ndarray, np.ndarray], tuple[np.ndarray, np.ndarray]]:\n",
    "    i = int(len(y) * 0.8)\n",
    "    return (x[:i], y[:i]), (x[i:], y[i:])\n",
    "\n",
    "\n",
    "# Read labels\n",
    "labels: np.ndarray\n",
    "with open(label_path, \"rb\") as f:\n",
    "    labels = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "\n",
    "# Read digits\n",
    "digits: np.ndarray\n",
    "size = 28*28\n",
    "with open(digits_path, \"rb\") as f:\n",
    "    digit_buffer = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "\n",
    "    num_images = len(labels)\n",
    "    digits = np.empty((num_images, 28, 28))\n",
    "\n",
    "    for n in range(num_images):\n",
    "        img = digit_buffer[n*size:(n+1)*size]\n",
    "        img = img.reshape((28, 28))\n",
    "        digits[n] = img\n",
    "\n",
    "\n",
    "# Remove all zeroes\n",
    "zero_mask = np.where(labels != 0)\n",
    "labels = labels[zero_mask]\n",
    "digits = digits[zero_mask]\n",
    "\n",
    "# Split into train and test\n",
    "(x_train, y_train), (x_test, y_test) = split_data(digits, labels)\n",
    "\n",
    "y_train -= 1\n",
    "y_test -= 1\n",
    "\n",
    "x_train = x_train.astype(np.float32) / 255.0\n",
    "x_test = x_test.astype(np.float32) / 255.0\n",
    "\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "            featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "            samplewise_center=False,  # set each sample mean to 0\n",
    "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "            samplewise_std_normalization=False,  # divide each input by its std\n",
    "            zca_whitening=False,  # apply ZCA whitening\n",
    "            rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "            zoom_range = 0.1, # Randomly zoom image \n",
    "            width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "            height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "            horizontal_flip=False,  # randomly flip images\n",
    "            vertical_flip=False)  # randomly flip images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes=9)\n",
    "y_test = to_categorical(y_test, num_classes=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', strides=1, padding='same', data_format='channels_last',\n",
    "                 input_shape=(28,28,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', strides=1, padding='same', data_format='channels_last'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid' ))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', strides=1, padding='same', data_format='channels_last'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), strides=1, padding='same', activation='relu', data_format='channels_last'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), padding='valid', strides=2))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(9, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " batch_normalization_18 (Ba  (None, 28, 28, 32)        128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 28, 28, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_19 (Ba  (None, 28, 28, 32)        128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPoolin  (None, 14, 14, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 14, 14, 32)        0         \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 14, 14, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_20 (Ba  (None, 14, 14, 64)        256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 14, 14, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_21 (Ba  (None, 14, 14, 64)        256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPoolin  (None, 7, 7, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 7, 7, 64)          0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 3136)              0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 512)               1606144   \n",
      "                                                                 \n",
      " batch_normalization_22 (Ba  (None, 512)               2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1024)              525312    \n",
      "                                                                 \n",
      " batch_normalization_23 (Ba  (None, 1024)              4096      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 9)                 9225      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2212585 (8.44 MB)\n",
      "Trainable params: 2209129 (8.43 MB)\n",
      "Non-trainable params: 3456 (13.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
    "model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-23 23:28:59.029646: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Adam/AssignAddVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 3s 31ms/step - loss: 1.8386 - accuracy: 0.4985 - val_loss: 6.3584 - val_accuracy: 0.0747\n",
      "Epoch 2/50\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.6122 - accuracy: 0.8018 - val_loss: 10.2483 - val_accuracy: 0.0747\n",
      "Epoch 3/50\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.2921 - accuracy: 0.9055 - val_loss: 6.8159 - val_accuracy: 0.0747\n",
      "Epoch 4/50\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.1660 - accuracy: 0.9440 - val_loss: 6.7318 - val_accuracy: 0.0747\n",
      "Epoch 5/50\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.1411 - accuracy: 0.9619 - val_loss: 6.1459 - val_accuracy: 0.1646\n",
      "Epoch 6/50\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0828 - accuracy: 0.9718 - val_loss: 5.7015 - val_accuracy: 0.0777\n",
      "Epoch 7/50\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0698 - accuracy: 0.9794 - val_loss: 4.8829 - val_accuracy: 0.2348\n",
      "Epoch 8/50\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 0.0795 - accuracy: 0.9783 - val_loss: 3.5713 - val_accuracy: 0.3720\n",
      "Epoch 9/50\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0604 - accuracy: 0.9829 - val_loss: 3.4114 - val_accuracy: 0.4451\n",
      "Epoch 10/50\n",
      "41/41 [==============================] - 1s 30ms/step - loss: 0.0557 - accuracy: 0.9836 - val_loss: 2.1221 - val_accuracy: 0.5213\n",
      "Epoch 11/50\n",
      "41/41 [==============================] - 1s 29ms/step - loss: 0.0596 - accuracy: 0.9829 - val_loss: 1.3246 - val_accuracy: 0.5976\n",
      "Epoch 12/50\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 0.0797 - accuracy: 0.9783 - val_loss: 1.3378 - val_accuracy: 0.6037\n",
      "Epoch 13/50\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 0.0667 - accuracy: 0.9832 - val_loss: 0.2223 - val_accuracy: 0.9436\n",
      "Epoch 14/50\n",
      "41/41 [==============================] - 1s 29ms/step - loss: 0.0459 - accuracy: 0.9893 - val_loss: 0.1420 - val_accuracy: 0.9665\n",
      "Epoch 15/50\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 0.0482 - accuracy: 0.9909 - val_loss: 0.1002 - val_accuracy: 0.9817\n",
      "Epoch 16/50\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0468 - accuracy: 0.9878 - val_loss: 0.1588 - val_accuracy: 0.9588\n",
      "Epoch 17/50\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 0.0393 - accuracy: 0.9920 - val_loss: 0.1030 - val_accuracy: 0.9893\n",
      "Epoch 18/50\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 0.0399 - accuracy: 0.9931 - val_loss: 0.0986 - val_accuracy: 0.9878\n",
      "Epoch 19/50\n",
      "41/41 [==============================] - 1s 32ms/step - loss: 0.0319 - accuracy: 0.9924 - val_loss: 0.0904 - val_accuracy: 0.9924\n",
      "Epoch 20/50\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 0.0340 - accuracy: 0.9928 - val_loss: 0.1187 - val_accuracy: 0.9939\n",
      "Epoch 21/50\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 0.0345 - accuracy: 0.9935 - val_loss: 0.1147 - val_accuracy: 0.9909\n",
      "Epoch 22/50\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 0.0321 - accuracy: 0.9935 - val_loss: 0.1023 - val_accuracy: 0.9939\n",
      "Epoch 23/50\n",
      "41/41 [==============================] - 1s 29ms/step - loss: 0.0335 - accuracy: 0.9920 - val_loss: 0.1028 - val_accuracy: 0.9939\n",
      "Epoch 24/50\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 0.0327 - accuracy: 0.9920 - val_loss: 0.1036 - val_accuracy: 0.9924\n",
      "Epoch 25/50\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0292 - accuracy: 0.9950 - val_loss: 0.0940 - val_accuracy: 0.9939\n",
      "Epoch 26/50\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0291 - accuracy: 0.9916 - val_loss: 0.1064 - val_accuracy: 0.9893\n",
      "Epoch 27/50\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 0.0345 - accuracy: 0.9920 - val_loss: 0.0939 - val_accuracy: 0.9939\n",
      "Epoch 28/50\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 0.0411 - accuracy: 0.9886 - val_loss: 0.1206 - val_accuracy: 0.9924\n",
      "Epoch 29/50\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 0.0323 - accuracy: 0.9916 - val_loss: 0.1215 - val_accuracy: 0.9939\n",
      "Epoch 30/50\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 0.0300 - accuracy: 0.9950 - val_loss: 0.1007 - val_accuracy: 0.9924\n",
      "Epoch 31/50\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 0.0225 - accuracy: 0.9958 - val_loss: 0.1068 - val_accuracy: 0.9924\n",
      "Epoch 32/50\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0358 - accuracy: 0.9905 - val_loss: 0.1338 - val_accuracy: 0.9695\n",
      "Epoch 33/50\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0287 - accuracy: 0.9950 - val_loss: 0.1390 - val_accuracy: 0.9878\n",
      "Epoch 34/50\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0230 - accuracy: 0.9966 - val_loss: 0.1476 - val_accuracy: 0.9909\n",
      "Epoch 35/50\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0236 - accuracy: 0.9950 - val_loss: 0.0975 - val_accuracy: 0.9924\n",
      "Epoch 36/50\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0319 - accuracy: 0.9947 - val_loss: 0.0937 - val_accuracy: 0.9924\n",
      "Epoch 37/50\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0228 - accuracy: 0.9962 - val_loss: 0.1016 - val_accuracy: 0.9909\n",
      "Epoch 38/50\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 0.0254 - accuracy: 0.9947 - val_loss: 0.0994 - val_accuracy: 0.9924\n",
      "Epoch 39/50\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 0.0549 - accuracy: 0.9889 - val_loss: 0.0960 - val_accuracy: 0.9924\n",
      "Epoch 40/50\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0317 - accuracy: 0.9928 - val_loss: 0.1014 - val_accuracy: 0.9939\n",
      "Epoch 41/50\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0261 - accuracy: 0.9947 - val_loss: 0.1075 - val_accuracy: 0.9939\n",
      "Epoch 42/50\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0259 - accuracy: 0.9928 - val_loss: 0.1097 - val_accuracy: 0.9939\n",
      "Epoch 43/50\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 0.0368 - accuracy: 0.9935 - val_loss: 0.1069 - val_accuracy: 0.9939\n",
      "Epoch 44/50\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0248 - accuracy: 0.9935 - val_loss: 0.0942 - val_accuracy: 0.9939\n",
      "Epoch 45/50\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 0.0327 - accuracy: 0.9950 - val_loss: 0.1055 - val_accuracy: 0.9939\n",
      "Epoch 46/50\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0234 - accuracy: 0.9950 - val_loss: 0.0939 - val_accuracy: 0.9878\n",
      "Epoch 47/50\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 0.0262 - accuracy: 0.9943 - val_loss: 0.1209 - val_accuracy: 0.9939\n",
      "Epoch 48/50\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0260 - accuracy: 0.9950 - val_loss: 0.1260 - val_accuracy: 0.9939\n",
      "Epoch 49/50\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0174 - accuracy: 0.9973 - val_loss: 0.1277 - val_accuracy: 0.9893\n",
      "Epoch 50/50\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0297 - accuracy: 0.9928 - val_loss: 0.1577 - val_accuracy: 0.9848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1606d9f90>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(datagen.flow(x_train, y_train, batch_size = batch_size), epochs = epochs, \n",
    "                              validation_data = (x_test, y_test), verbose=1, \n",
    "                              steps_per_epoch=x_train.shape[0] // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfjs.converters.save_keras_model(model, \"./models/tfjs_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
